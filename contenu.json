[{
    "0": "Nguon Celebration",
    "1": "Nguon Celebration is a tribute to the Nguon Festival, a Cameroonian festival showcasing Bamoun culture. <br>The virtual as a media allowed me to represent Bamoun objects in a non-static way but also to get out of reality by having a creative freedom. Thanks to a work of archive and conception of these objects, I was able to create an original universe transmitting the atmosphere of this festival.",
     "2": "2017, Video VR",
    "3": "Nguon/1.png,Nguon/2.png,Nguon/objets.mp4",
    "4": "20"
},
{
    "0": "Main Clé",
    "1": "Main Clé is a learning platform for LPC, the french Cued Speech. LPC is a sign language using the hands and face of the speaker as a supplement to lip-reading so as to communicate with deaf or hard of hearing people. The hand will take on a shape representing the consonant of a syllable and the position the hand takes around the face represents the vowel. The synchronisation of the gesture with speech necessary. The proposed pedagogical method allows the user to learn and practice through practical and fun exercises. Thanks to machine learning, Main Clé sends the user feedback about their gestures and their training to allow them to monitor their progress.",
    "2": "2019, Website",
    "3": "MainCle/0.png,MainCle/1.png,MainCle/2.png,MainCle/3.png,MainCle/4.png",
    "4": "90"
},
{
    "0": "Iris",
    "1": "Iris is a research project on the transmission of emotions from abstract visuals.<br>During my studies at ECAL, I had the opportunity to answer to the issue raised by Samsung: what to do with our TV screens when the users are not looking at them? With Clara Aboulker and Thomas Prost, we started from the premise that people leave their TV on in order to have a presence. So, we create Iris, an intelligent creation capable of expressing feelings such as joy, sadness, anger...<br>Her character is modulated according to a motion detector which is the only way to communicate with her. Opposites to a utility application such as Siri or Bixby, it is possible to listen to her think, questions, anecdotes. Iris is an application focused on the emotional, offering a sensitive experience. One of the main challenges was to give substance to this artificial presence. From which parameters is it possible to transmit an emotion? What visual language should be developed for this application? We answered this question by creating a library of voices, shapes, movements, colors, which associated thanks to shaders would create her body.",
    "2": "2018, Research project",
    "3": "Iris/0b.png,Iris/4.mp4,Iris/2.mp4,Iris/3.mp4",
    "4": "120"
},
{
    "0": "Wuta",
    "1": "Wuta is an interactive installation. It represents an avatar who tries to decrypt what his interlocutor is telling him. Wuta can neither hear nor read lips, so he uses the basis of the Completed Spoken Language, the French Cued Speed, a sign language using the hands and face of the speaker as a supplement to lip-reading so as to communicate with deaf or hard of hearing people. He uses the shape emitted by the hand through a leapmotion and the position of the hand through an image recognition system. Thanks to a machine learning system, it is possible to configure its learning. Once the message has been decoded, Wuta proposes a series of words that he has been able to understand.",
    "2": "2018, Interactive Installation",
    "3": "Wuta/0.png,Wuta/Wuta.mp4",
    "4": "60"
},
{
    "0": "The Human Detector",
    "1": "The Human Detector is an experience that invites the user to do everything in order to avoid being recognised by AI. The aim of the experience is for the user to press a button without being detected as a human being by a camera connected to a detection system. The project was born from personal experience about racial biases in face detection tools.I first discovered machine learning during a week-long workshop with New York–based programmer and artist Gene Kogan at ECAL. The start of the week proved complicated for me, as I could not test all the examples from ml4a (Machine Learning for Artists; one of the many tools artists have to use machine learning programs). The reason for this was that the facial detection algorithms were struggling to detect me, and the reason they were struggling to detect me is because I’m black. I had to be very creative to be detected so during the workshop, I created the Human Detector. By doing this, I recreated my own experience with ml4a and AI, but I inverted the rules so that I win every time. The Human Detector invites the user to question himself around the biases carried by technologies through a playful and creative experience.",
    "2": "2018, Interactive Installation",
    "3": "HumanDetector/TheHumanDetector.png,HumanDetector/TheHumanDetectorC.png,HumanDetector/HumanDetector.mp4",
    "4": "140"
}]